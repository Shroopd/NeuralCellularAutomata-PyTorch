# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = [
    "def_device",
    "CHANNEL_N",
    "TARGET_PADDING",
    "TARGET_SIZE",
    "POOL_SIZE",
    "CELL_FIRE_RATE",
    "filters",
    "load_image",
    "perchannel_conv",
    "alive",
    "CAModel",
    "display_animation",
    "grow_animation",
]

# %% ../nbs/00_core.ipynb 3
from PIL import Image

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

from IPython.display import HTML

import fastcore.all as fc

from functools import partial
import torch
import torch.nn as nn
import torch.nn.functional as F

from NeuralCellularAutomata_PyTorch.custom_attention import (
    CustomAttention,
    Conv2DAttention,
)

# %% ../nbs/00_core.ipynb 5
# setting a default device
def_device = (
    "mps"
    if torch.backends.mps.is_available()
    else "cuda"
    if torch.cuda.is_available()
    else "cpu"
)

# %% ../nbs/00_core.ipynb 7
CHANNEL_N = 8
COLOR_N = 3
TARGET_PADDING = 16
TARGET_SIZE = 40

POOL_SIZE = 1024
CELL_FIRE_RATE = 0.5


# %% ../nbs/00_core.ipynb 11
def load_image(path):
    "Load the image specified by `path` and return a `torch.tensor` version of the image with shape B, C, H, W, already on the default device"

    img = Image.open(path).resize((TARGET_SIZE, TARGET_SIZE))
    # Convert the image to numpy array
    img = np.array(img)[...,:COLOR_N]
    img = img.astype(np.float32) / 255.0

    # Display the image
    plt.imshow(img)
    plt.show()

    img_tensor = torch.tensor(img).permute(2, 0, 1)[None].to(def_device)

    return img_tensor


# %% ../nbs/00_core.ipynb 14
filters = torch.stack(
    [
        torch.tensor(
            [[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]]
        ),  # Identity filter
        torch.tensor(
            [[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]]
        ),  # Vertical sobel filter
        torch.tensor(
            [[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]]
        ).T,  # Horizontal sobel filter
    ]
).to(def_device)


# %% ../nbs/00_core.ipynb 17
def perchannel_conv(x, filters):
    b, c, h, w = x.shape
    y = x.reshape(b * c, 1, h, w)
    y = F.pad(y, (1, 1, 1, 1), mode="circular")
    y = F.conv2d(y, filters[:, None])
    return y.reshape(b, -1, h, w)


# %% ../nbs/00_core.ipynb 22
def alive(x, threshold=0.1):
    x = F.pad(x, (1, 1, 1, 1), mode="circular")
    return F.max_pool2d(x, 3, stride=1, padding=0) > threshold


# %% ../nbs/00_core.ipynb 23
class CAModel(nn.Module):
    def __init__(self, channel_n, update_rate=0.9):
        super().__init__()

        self.channel_n = channel_n
        self.update_rate = update_rate

        self.brain = nn.Sequential(
            # nn.Conv2d(channel_n * 3, 128, kernel_size=1),  # pixel-wise mlp
            # nn.SiLU(),
            # nn.Conv2d(128, self.channel_n, kernel_size=1, bias=False),
            nn.Linear(self.channel_n, self.channel_n * 2, False),  # pixel-wise mlp
            nn.SiLU(),
            # nn.Linear(self.channel_n * 2, self.channel_n * 2, False),  # pixel-wise mlp
            # nn.SiLU(),
            # nn.Linear(self.channel_n * 2, self.channel_n * 4, False),  # pixel-wise mlp
            # nn.SiLU(),
            nn.Linear(self.channel_n * 2, self.channel_n * 2, False),  # pixel-wise mlp
            nn.SiLU(),
            nn.Linear(self.channel_n * 2, self.channel_n, False),
            # nn.Tanh()
        )

        # NOTE: changed stuff here
        heads = 8

        foo = CustomAttention(heads, channel_n, channel_n // heads)
        self.attention = Conv2DAttention(foo)
        # self.attention = Conv2DAttention()

        # this network is used to calculate the change of the features, so initially, we dont want to suggest any changes
        # thus we set the output weights to zero
        # with torch.no_grad():  # NOTE an ignore here
        #     # self.brain[-4].weight.zero_()  # type: ignore
        #     self.brain[-2].weight.zero_()  # type: ignore

    def step(self, x, update_rate=None):

        # -- Update by neighbors -- (apply the filters to the input)
        y: torch.Tensor = self.attention(x)

        update_rate = (
            update_rate or self.update_rate
        )  # if update_rate is not given, use the default value
        update_mask = (torch.rand(x.shape).to(def_device) + update_rate).floor()

        x = x + y * update_mask  # update only a fraction of the cells
        # x = x + y

        # -- Update by self -- (pass the input through the brain)
        x = self.brain(x.movedim(1, -1)).movedim(-1, 1)

        # y = self.brain(y.movedim(1, -1)).movedim(-1, 1)

        # -- Clamp values --

        return x

    def forward(self, x, steps=1, update_rate=None):
        for i in range(steps):
            x = self.step(x, update_rate=update_rate)
        return x


# %% ../nbs/00_core.ipynb 28
def display_animation(
    images,
):  # A list containing the frames of the animation. Each frame should be of shape [H, W, 4]
    fig = plt.figure(figsize=(6, 6))
    plt.axis("off")
    ims = [[plt.imshow(image, animated=True)] for image in images]
    # display animation in jupyter notebook
    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)
    plt.close()
    # display HTML
    return HTML(ani.to_jshtml())


# %% ../nbs/00_core.ipynb 31
@fc.patch
def grow_animation(self: CAModel, seed, steps, update_rate=None):
    x = seed.clone()
    images = [torch.clamp(x[0, :COLOR_N].detach().cpu().permute(1, 2, 0), 0, 1)]
    for _ in range(steps):
        x = self.step(x, update_rate=update_rate)
        images.append(torch.clamp(x[0, :COLOR_N].detach().cpu().permute(1, 2, 0), 0, 1))
    return images
